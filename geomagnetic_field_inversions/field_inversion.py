import numpy as np
from scipy.interpolate import BSpline, interp1d
import scipy.sparse as scs
import scipy.linalg as scl
import pandas as pd
from typing import Union, Final
from pathlib import Path
from tqdm import tqdm

from .data_prep import StationData
from .forward_modules import frechet, fwtools
from .damping_modules import damping
from .tools.core import latrad_in_geoc, frechet_in_geoc


class FieldInversion:
    """
    Calculates geomagnetic field coefficients based on inputted data and
    damping parameters using the approach of Korte et al.
    """

    def __init__(self,
                 time_array: Union[list, np.ndarray],
                 maxdegree: int = 3,
                 r_model: float = 6371.2,
                 verbose: bool = False
                 ) -> None:
        """
        Initializes the Field Inversion class

        Parameters
        ----------
        time_array
            Sets timearray for the inversion in yr. Should be ascending
        maxdegree
            maximum order for spherical harmonics model, default 3
        r_model
            where the magnetic field is modeled (km distance from core)
        verbose
            Verbosity flag, defaults to False
        """
        # basic parameters
        self._SPL_DEGREE: Final[int] = 3

        # input parameters
        self.t_array = np.sort(time_array)
        self.maxdegree = maxdegree
        self.r_model = r_model
        self.verbose = verbose

        # initiate empty variables
        self.time_array = []
        self.data_array = []
        self.error_array = []
        self.types = []
        self.unsplined_iter_gh = []
        self.dcname = []  # contains name of stations
        self.bspl_func = []
        self.stat_ix = []
        self.time_ix = []
        self.sc = 0  # station count
        self.types_ready = False
        self.types_sorted = np.zeros(0)
        self.count_type = np.zeros(7)
        self.station_coord = np.zeros((0, 3))
        self.gcgd_conv = np.zeros((0, 2))
        self.damp_matrix = np.zeros(0)
        self.spat_norm = np.zeros(0)
        self.spat_type = np.zeros(0)
        self.temp_norm = np.zeros(0)
        self.temp_type = np.zeros(0)
        self.splined_gh = np.zeros(0)
        self.station_frechet = np.zeros(0)
        self.res_iter = np.zeros(0)
        self.x0 = np.zeros(0)

    @property
    def maxdegree(self):
        return self._maxdegree

    @maxdegree.setter
    def maxdegree(self, degree: int):
        # determines the maximum number of spherical coefficients
        self._nm_total = int((degree+1)**2 - 1)
        self._maxdegree = int(degree)
        self.spat_fac = np.zeros(self._nm_total)  # contains damping factors
        self.temp_fac = np.zeros(self._nm_total)
        self.matrix_ready = False

    @property
    def t_array(self):
        return self._t_array

    @t_array.setter
    def t_array(self, array: Union[list, np.ndarray]):
        # check time array
        if len(array) == 1:
            raise Exception('t_array should consist or more than one timestep')
        self._t_step = array[1] - array[0]
        self._t_array = array
        # number of temporal splines
        self.nr_splines = len(self.t_array) + self._SPL_DEGREE - 1
        # location of timeknots with small deviation for correct splines
        self.time_knots = np.linspace(
            self.t_array[0] - self._SPL_DEGREE * self._t_step * (1 + 1e-12),
            self.t_array[-1] + self._SPL_DEGREE * self._t_step * (1 + 1e-12),
            num=len(self.t_array) + 2 * self._SPL_DEGREE)
        # check for equally spaced time array
        for i in range(len(array)-1):
            step = self._t_array[i+1] - self._t_array[i]
            if abs(step - self._t_step) > self._t_step * 1e-12:
                raise Exception("Time vector has different timesteps. "
                                " Redefine vector with same timestep. "
                                f"Difference: {abs(step - self._t_step)}")
        self.times = len(array)
        self.matrix_ready = False

    def add_data(self,
                 data_class: StationData,
                 ) -> None:
        """
        Adds data generated by the Station_data class

        Parameters
        ----------
        data_class
            instance of the Station_data class. Only added if it matches the
            time_array set in __init__

        Creates or modifies
        -------------------
        self.data_array
            contains the measurements per site
            size= (# datatypes, len(measurements)) (floats)
        self.error_array
            contains the error in measurements per site
            size= (# datatypes, len(measurements)) (floats)
        self.types
            contains the type of all data in one long list
            size= # datatypes (integers)
        self.station_coord
            contains the colatitude, longitude, and radius of station
            size= (# datatypes, 3) (floats)
        self.gcgd_conv
            contains conversion factors for geodetic to geocentric conversion
            of magnetic components mx/dx and mz/dz
            size= (# datatypes, 2) (floats)
        self.types_ready
            boolean indicating if datatypes (self.types) are logically sorted
        """
        # translation datatypes
        typedict = {"x": 0, "y": 1, "z": 2, "hor": 3,
                    "int": 4, "inc": 5, "dec": 6}
        if not isinstance(data_class, StationData):
            raise Exception('data_class is not an instance of Station_Data')
        # set up empty arrays
        time_entry = []
        data_entry = []
        error_entry = []
        types_entry = []
        name = data_class.__name__
        for c, types in enumerate(data_class.types):
            # check if data covers any spline
            if data_class.data[c][0][-1] < self.time_knots[0]\
                    or data_class.data[c][0][0] > self.time_knots[-1]:
                raise Exception(f'{types} of {name} does not cover'
                                ' any timestep of timeknots')

            # Extract data from StationData-class
            if self.verbose:
                print(f'Adding {types}-type')
            # temporary data and error storage
            temp_d = data_class.data[c][1]
            temp_e = data_class.data[c][2]
            if types == 'inc' or types == 'dec':
                # transform incl/decl data to radians
                temp_d = np.radians(temp_d)
                temp_e = np.radians(temp_e)

            # add data, error, and type to arrays
            time_entry.append(data_class.data[c][0])
            data_entry.append(temp_d)
            error_entry.append(temp_e)
            # count occurrence datatype and add to list
            types_entry.append(typedict[types])

        # change coordinates from geodetic to geocentric if required
        if data_class.geodetic:
            if self.verbose:
                print(f'Coordinates are geodetic,'
                      ' translating to geocentric coordinates.')
            lat_geoc, r_geoc, cd, sd = latrad_in_geoc(
                np.radians(data_class.lat), data_class.height)
            station_entry = np.array([0.5*np.pi - lat_geoc,
                                      np.radians(data_class.lon),
                                      r_geoc])
        else:
            if self.verbose:
                print(f'Coordinates are geocentric,'
                      ' no translation required.')
            cd = 1.  # this will not change dx and dz when forming frechet
            sd = 0.
            station_entry = np.array([0.5*np.pi-np.radians(data_class.lat),
                                      np.radians(data_class.lon),
                                      6371.2+data_class.height*1e-3])

        # add data to attributes of the class if all is fine
        if self.verbose:
            print(f'Data of {name} is added to class')
        self.dcname.append(name)
        self.time_array.extend(time_entry)
        self.data_array.extend(data_entry)
        self.error_array.extend(error_entry)
        self.types.append(types_entry)  # is now one long list
        self.station_coord = np.vstack((self.station_coord, station_entry))
        self.gcgd_conv = np.vstack((self.gcgd_conv, np.array([cd, sd])))
        self.types_ready = False
        # station counter
        self.sc += 1

    def prepare_inversion(self,
                          spat_fac: float = 0,
                          temp_fac: float = 0,
                          spat_type: int = 3,
                          temp_type: int = 7,
                          spat_ddip: bool = False,
                          temp_ddip: bool = True
                          ) -> None:
        """
        Function to prepare matrices for the inversion

        Parameters
        ----------
        spat_fac, temp_fac
            damping factor to be applied to the total damping matrix
        spat_type, temp_type
            integer corresponding to applied damping type
            defaults, respectively, to minimize Ohmic heat and acceleration
            magnetic field, both at cmb
        spat_ddip, temp_ddip
            boolean indicating whether to damp dipole coefficients.

        Creates or modifies
        -------------------
        self.spatdamp, self.tempdamp
            saves type of damping used
        self.station_frechet
            contains frechet matrix per location
            size= ((# stations x 3), nm_total) (floats)
        self.spat_fac, self.temp_fac
            contains the damping elements dependent on degree
             size= nm_total (floats) (see damp_types.py)
        self.spat_damp_matrix
            contains symmetric spatial damping matrix
            size= (nm_total x nr_splines, nm_total x nr_splines) (floats)
        self.temp_damp_matrix
            contains symmetric temporal damping matrix
            size= (nm_total x nr_splines, nm_total x nr_splines) (floats)
        self.matrix_ready
            indicates whether all matrices have been formed (boolean)
        self.types_ready
            boolean indicating if datatypes (self.types) are logically sorted
        """
        # order data per spline
        self.stat_ix = [[] for _ in range(len(self.t_array))]
        self.time_ix = [[] for _ in range(len(self.t_array))]
        # loop through dataset
        for index, time_array in enumerate(self.time_array):
            # loop through individual times
            for t_index, time in enumerate(time_array):
                nleft = int((time - self._t_array[0]) // self._t_step)
                if 0 <= nleft < len(self._t_array) and time <= self._t_array[-1]:
                    # index corresponds to time, data, and error
                    # add index of station
                    self.stat_ix[nleft].append(index)
                    # add index of data per station to spline
                    self.time_ix[nleft].append(t_index)

        # prepare BSplines
        self.bspl_func = [[] for _ in range(self.nr_splines)]
        for spl in range(self.nr_splines):
            self.bspl_func[spl] = BSpline.basis_element(
                self.time_knots[spl:spl+self._SPL_DEGREE+2], extrapolate=False)

        # order datatypes in a more straightforward way
        # line of types_sorted corresponds to index
        if not self.types_ready:
            self.types_sorted = []
            for nr, stat in enumerate(self.types):
                for datum in stat:  # datum is 0 to 6
                    self.types_sorted.append(7*nr + datum)
            self.types_sorted = np.array(self.types_sorted)
            self.types_ready = True

        self.count_type = np.zeros(7)
        for tix in range(len(self._t_array)):
            # use stations to make frechet for spline
            datapts = (self.types_sorted[self.stat_ix[tix]] % 7).astype(int)
            if not self.stat_ix[tix] and tix != len(self._t_array)-1:
                print(f'Warning: no data between {self._t_array[tix]}'
                      f' and {self._t_array[tix+1]}')
            for i in range(7):
                index = np.where(datapts == i)[0]
                self.count_type[i] += np.sum(len(index))

        # calculate frechet dx, dy, dz for all stations
        if self.verbose:
            print('Calculating Schmidt polynomials and FrÃ©chet coefficients')
        self.station_frechet = frechet.frechet_basis(
            self.station_coord, self._maxdegree)
        # geocentric correction
        dx, dz = frechet_in_geoc(
            self.station_frechet[:, 0], self.station_frechet[:, 2],
            self.gcgd_conv[:, 0], self.gcgd_conv[:, 1])
        self.station_frechet[:, 0] = dx
        self.station_frechet[:, 2] = dz

        # Prepare damping matrices
        self.damp_matrix = np.zeros(
            (2 * self._SPL_DEGREE + 1, self.nr_splines * self._nm_total))
        if spat_fac != 0 and self._t_step != 0:
            if self.verbose:
                print('Calculating spatial damping matrix')
            self.spat_fac = spat_fac
            self.spat_type = spat_type
            spat_damp_diag, self.spat_fac = damping.damp_matrix(
                self._maxdegree, self.nr_splines, self._t_step,
                spat_fac, spat_type, spat_ddip)
            self.damp_matrix += spat_damp_diag
        if temp_fac != 0 and self._t_step != 0:
            if self.verbose:
                print('Calculating temporal damping matrix')
            self.temp_fac = temp_fac
            self.temp_type = temp_type
            temp_damp_diag, self.temp_fac = damping.damp_matrix(
                self._maxdegree, self.nr_splines, self._t_step,
                temp_fac, temp_type, temp_ddip)
            self.damp_matrix += temp_damp_diag

        self.matrix_ready = True
        if self.verbose:
            print('Calculations finished')

    def run_inversion(self,
                      x0: np.ndarray,
                      max_iter: int = 10,
                      stop_crit: float = -np.inf,
                      path: Path = None,
                      ) -> None:
        """
        Runs the iterative inversion

        Parameters
        ----------
        x0
            starting model gaussian coefficients, should have length:
            (spherical_order + 1)^2 - 1 or
            (spherical_order + 1)^2 - 1 X nr_splines if changing through time
        max_iter
            If integer, maximum amount of iterations.
        stop_crit
            stopping criterion for iterations. Iterations will stop if
            relative change of residual is less than given float (between 0-1).
        path
            path to location where to save normal_eq_splined and damp_matrix
            for calculating optional covariance and resolution matrix.
            If not provided, matrices are not solved.
            See calc_stdev in tools/core

        Creates or modifies
        -------------------
        self.res_iter
             contains the RMS per datatype and the sum of all types
             size= 8 (floats)
        self.unsplined_iter_gh
            contains the BSpline function to unspline Gauss coeffs at any
            requested time (within range) for every iteration
            size= # iterations (BSpline functions)
        self.splined_gh
            contains the splined Gauss coeffs at all times of current iteration
            size= (len(nr_splines), nm_total) (floats)
        """
        if not self.matrix_ready:
            raise Exception('Matrices have not been prepared. '
                            'Please run prepare_inversion first.')
        # create even array with pandas then convert to numpy
        data_array = pd.DataFrame(self.data_array).to_numpy()
        time_array = pd.DataFrame(self.time_array).to_numpy()
        error_array = pd.DataFrame(self.error_array).to_numpy()
        # initiate array counting residual per type
        self.res_iter = np.zeros((max_iter+1, 8))
        # initiate splined values with starting model
        if self.verbose:
            print('Setting up starting model')
        self.splined_gh = np.zeros((self.nr_splines, self._nm_total))
        self.unsplined_iter_gh = []
        if x0.ndim == 1 and len(x0) == self._nm_total:
            self.x0 = x0.copy()
            self.splined_gh[:] = x0
        else:
            raise Exception(f'x0 has incorrect shape: {x0.shape}. \n'
                            f'It should have shape ({self._nm_total},) or'
                            f' ({self.nr_splines}, {self._nm_total})')

        spacing = self._nm_total * self._SPL_DEGREE
        sparse_damp = scs.dia_matrix(
            (self.damp_matrix,
             np.linspace(spacing, -spacing, 2*self._SPL_DEGREE+1)),
            shape=(len(self.damp_matrix[0]), len(self.damp_matrix[0])))
        for it in range(max_iter+1):  # start outer iteration loop
            res_iter = np.zeros(7)
            if self.verbose:
                print(f'Start calculations iteration {it+1}')
            rhs_array = np.zeros(self.nr_splines * self._nm_total)
            normal_eq_splined = np.zeros((self._nm_total * self.nr_splines,
                                          self._nm_total * self.nr_splines))

            rhs_damp = -sparse_damp.dot(self.splined_gh.flatten())

            gh_splfunc = BSpline(c=self.splined_gh, t=self.time_knots,
                                 k=self._SPL_DEGREE, extrapolate=False)
            # Calculate frechet and residual matrix for all times
            for tix in range(len(self._t_array)):
                # use stations to make frechet for spline
                datapoints = self.types_sorted[self.stat_ix[tix]]
                if not self.stat_ix[tix]:
                    continue

                station_nr = (datapoints // 7).astype(int)
                # contains all observational data in 7 rows
                forwobs_matrix = fwtools.forward_obs(gh_splfunc(
                    time_array[self.stat_ix[tix], self.time_ix[tix]]),
                    self.station_frechet, link=station_nr)
                # contains location per row
                frech_matrix = frechet.frechet_types(
                    self.station_frechet[station_nr], forwobs_matrix)
                frech_matrix = frech_matrix[np.arange(len(datapoints)),
                                            datapoints % 7].reshape(
                    len(datapoints), self._nm_total)
                # contains one row with all residuals
                res_matrix = fwtools.residual_obs(
                    forwobs_matrix[datapoints % 7, np.arange(len(datapoints))],
                    data_array[self.stat_ix[tix], self.time_ix[tix]],
                    datapoints)
                res_weight = res_matrix / error_array[self.stat_ix[tix],
                                                      self.time_ix[tix]]
                for i in range(7):
                    index = np.where(station_nr % 7 == i)[0]
                    res_iter[i] += sum(res_weight[index]**2)

                # create rhs vector
                spl_range = range(tix, min(tix + self._SPL_DEGREE + 1,
                                           self.nr_splines))
                ext_frechet = np.zeros((len(self.stat_ix[tix]),
                                        self._nm_total * len(spl_range)))
                time = time_array[self.stat_ix[tix], self.time_ix[tix]]
                err = error_array[self.stat_ix[tix], self.time_ix[tix]]
                for i, spl in enumerate(spl_range):
                    bspline = self.bspl_func[spl](time)
                    bspline[np.isnan(bspline)] = 0
                    ext_frechet[:, i*self._nm_total:(i+1)*self._nm_total] =\
                        frech_matrix * (bspline / err)[:, np.newaxis]
                begin = tix * self._nm_total
                end = (tix + self._SPL_DEGREE + 1) * self._nm_total
                rhs_array[begin:end] += np.matmul(ext_frechet.T, res_weight)
                normal_eq_splined[begin:end, begin:end] += np.matmul(
                    ext_frechet.T, ext_frechet)

            for i in range(7):
                if self.count_type[i] != 0:
                    self.res_iter[it, i] = np.sqrt(
                        res_iter[i] / self.count_type[i])
            self.res_iter[it, 7] = np.sqrt(sum(res_iter)/sum(self.count_type))
            if self.verbose:
                print('Residual is %.2f' % self.res_iter[it, 7])
            # check if final conditions have been met
            # XXX: This leads to 2 iterations, even if maxiter = 1
            if it > 0:
                rel_err = abs(self.res_iter[it, 7] - self.res_iter[it-1, 7]
                              ) / self.res_iter[it-1, 7]
                if stop_crit >= rel_err or it == max_iter:
                    if self.verbose:
                        print(f'Final iteration; relative error = {rel_err}')
                    break

            # solve the equations
            if self.verbose:
                print('Prepare and solve equations')
            # create diagonals for quick inversion
            diag = np.zeros(((self._SPL_DEGREE + 1) * self._nm_total * 2 - 1,
                             len(normal_eq_splined)))
            # number of upper diagonals
            hdiags = int((self._SPL_DEGREE + 1) * self._nm_total - 1)
            diag[hdiags] = np.diag(normal_eq_splined)
            # upper to lower diagonal
            for i in range(hdiags):
                diag[i, hdiags-i:] = np.diagonal(normal_eq_splined, hdiags-i)
                diag[-(i+1), :-(hdiags-i)] = np.diagonal(
                    normal_eq_splined, -(hdiags-i))
            # add damping to required diagonals
            damp_diags = np.linspace(hdiags-spacing, hdiags+spacing,
                                     2*self._SPL_DEGREE + 1, dtype=int)
            diag[damp_diags] += self.damp_matrix
            # add damping to the vector
            rhs_array += rhs_damp
            # solve banded system
            update = scl.solve_banded((hdiags, hdiags), diag, rhs_array)
            self.splined_gh = (self.splined_gh.flatten() + update).reshape(
                self.nr_splines, self._nm_total)
            # despline Gauss coefficients and form function
            spline = BSpline(t=self.time_knots, c=self.splined_gh,
                             k=3, axis=0, extrapolate=False)
            self.unsplined_iter_gh.append(spline)

        # sum residuals and finish up stuff
        if self.verbose:
            print('Calculating optional spatial and temporal norms')
        tsp = self._t_array[-1] - self._t_array[0]
        if np.any(self.spat_fac != 0):
            self.spat_norm = damping.damp_norm(self.spat_fac, self.splined_gh,
                                               self.spat_type, self._t_step)
            if self.verbose:
                print(f'Spatial damping norm: {np.sum(self.spat_norm) / tsp}')
        if np.any(self.temp_fac != 0):
            self.temp_norm = damping.damp_norm(self.temp_fac, self.splined_gh,
                                               self.temp_type, self._t_step)
            if self.verbose:
                print(f'Temporal damping norm: {np.sum(self.temp_norm) / tsp}')

        if path is not None:
            if self.verbose:
                print('Saving matrices')
            save_diag = np.zeros(((self._SPL_DEGREE+1) * self._nm_total*2 - 1,
                                  len(normal_eq_splined)))
            save_diag[hdiags] = np.diag(normal_eq_splined)
            # upper to lower diagonal
            for i in range(hdiags):
                save_diag[i, hdiags - i:] = np.diagonal(normal_eq_splined,
                                                        hdiags - i)
                save_diag[-(i + 1), :-(hdiags - i)] = np.diagonal(
                    normal_eq_splined, -(hdiags - i))
            dia_matrix = scs.dia_matrix(
                (save_diag, np.linspace(hdiags, -hdiags, 2*hdiags + 1)),
                shape=(len(self.damp_matrix[0]), len(self.damp_matrix[0])))
            scs.save_npz(path / 'forward_matrix', dia_matrix)
            scs.save_npz(path / 'damp_matrix', sparse_damp)

        if self.verbose:
            print('Finished inversion')

    def save_coefficients(self,
                          basedir: Union[Path, str] = '.',
                          file_name: str = 'coeff',
                          save_iterations: bool = True,
                          save_residual: bool = False,
                          save_dampnorm: bool = False,
                          ) -> None:
        """
        Save the Gauss coefficients at every timestep

        Parameters
        ----------
        basedir
            path where files will be saved
        file_name
            optional name to add to files
        save_iterations
            boolean indicating whether to save coefficients after
            each iteration. Is saved with the following shape:
             (# iterations, len(time vector), nm_total)
        save_residual
            boolean indicating whether to save the residuals of each timestep
        save_dampnorm
            boolean indicating whether to save the damping norm each timestep
        """
        # save residual
        if save_residual:
            residual_frame = pd.DataFrame(
                self.res_iter, columns=['res x', 'res y', 'res z', 'res hor',
                                        'res int', 'res incl', 'res decl',
                                        'res total'])
            residual_frame.to_csv(basedir / f'{file_name}_residual.csv',
                                  sep=';')

        if save_iterations:
            all_coeff = np.zeros((
                len(self.unsplined_iter_gh), self.times, self._nm_total))
            for i in range(len(self.unsplined_iter_gh)):
                all_coeff[i] = self.unsplined_iter_gh[i](self._t_array)
            np.save(basedir / f'{file_name}_all.npy', all_coeff)
        else:
            gh_time = self.unsplined_iter_gh[-1](self._t_array)
            np.save(basedir / f'{file_name}_final.npy', gh_time)
        if save_dampnorm:
            np.savez(basedir / f'{file_name}_damp.npz',
                     spat_norm=self.spat_norm,
                     temp_norm=self.temp_norm,
                     time_array=self._t_array)

    def sweep_damping(self,
                      x0: Union[list, np.ndarray],
                      spatial_range: Union[list, np.ndarray],
                      temporal_range: Union[list, np.ndarray],
                      spat_type: int = 3,
                      temp_type: int = 7,
                      spat_ddip: bool = False,
                      temp_ddip: bool = True,
                      max_iter: int = 10,
                      basedir: Path = Path().absolute(),
                      overwrite: bool = True
                      ) -> None:
        """ Sweep through damping parameters to find ideal set

        Parameters
        ----------
        x0
            starting model gaussian coefficients, should be a float or
            as long as (spherical_order + 1)^2 - 1
        spatial_range
            array or list to vary spatial damping parameters.
        temporal_range
            array or list to vary temporal damping parameters.
        spat_type, temp_type, spat_ddip, temp_ddip
            spotial damping type, temporal damping type, damping dipole for
            spatial and temporal damping. See prepare_inversion for more info
        max_iter
            maximum number of iterations. defaults to 5 iterations
        basedir
            path where files will be saved
        overwrite
            boolean indicating whether to overwrite existing files with
            exactly the same damping parameters. otherwise set of damping
            parameters is skipped over in the calculations.
        """
        for spatial_df in tqdm(spatial_range):
            spat_fac = spatial_df
            for temporal_df in temporal_range:
                temp_fac = temporal_df
                if overwrite or not (basedir / f'{spatial_df:.2e}s+'
                                               f'{temporal_df:.2e}t_final.npy'
                                     ).is_file():
                    self.prepare_inversion(spat_fac, temp_fac, spat_type,
                                           temp_type, spat_ddip, temp_ddip)
                    self.run_inversion(x0, max_iter)
                    self.save_coefficients(
                        file_name=f'{spatial_df:.2e}s+{temporal_df:.2e}t',
                        basedir=basedir, save_iterations=False,
                        save_residual=True, save_dampnorm=True)
